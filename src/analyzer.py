"""
SQL ê¸°ë°˜ ë¶„ì„ê¸°

ì—­í• : ì„ë² ë””ë“œ SQLì„ ì‹¤í–‰í•˜ì—¬ ìœ ì˜ë¯¸í•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
"""

import logging
from pathlib import Path
from typing import List, Dict

import pandas as pd
from sqlalchemy.engine import Engine
from sqlalchemy import text

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

PROJECT_ROOT = Path(__file__).resolve().parents[1]
SQL_DIR = PROJECT_ROOT / "sql"


def execute_query_from_file(engine: Engine, sql_file: Path, query_name: str) -> pd.DataFrame:
    """SQL íŒŒì¼ì—ì„œ íŠ¹ì • ì¿¼ë¦¬ë¥¼ ì½ì–´ì„œ ì‹¤í–‰ (ì„ë² ë””ë“œ SQL)"""

    with open(sql_file, "r", encoding="utf-8") as f:
        content = f.read()

    # ì¿¼ë¦¬ ì´ë¦„ìœ¼ë¡œ ì¿¼ë¦¬ ì¶”ì¶œ
    queries = {}
    current_query_name = None
    current_query_lines = []

    for line in content.split("\n"):
        if line.strip().startswith("-- [") and "]" in line:
            # ìƒˆë¡œìš´ ì¿¼ë¦¬ ì‹œì‘
            if current_query_name and current_query_lines:
                queries[current_query_name] = "\n".join(current_query_lines)
            current_query_name = line.split("[")[1].split("]")[0].strip()
            current_query_lines = []
        elif current_query_name and not line.strip().startswith("--"):
            current_query_lines.append(line)

    # ë§ˆì§€ë§‰ ì¿¼ë¦¬ ì €ì¥
    if current_query_name and current_query_lines:
        queries[current_query_name] = "\n".join(current_query_lines)

    if query_name not in queries:
        raise ValueError(f"ì¿¼ë¦¬ '{query_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    query = queries[query_name].strip().rstrip(";")

    with engine.connect() as conn:
        result = pd.read_sql_query(text(query), conn)

    logger.info(f"âœ“ SQL ì‹¤í–‰: {query_name} ({len(result)}í–‰)")
    return result


def run_all_insights(engine: Engine) -> Dict[str, pd.DataFrame]:
    """ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰"""

    insights = {}
    # SQLiteìš© ì¿¼ë¦¬ íŒŒì¼ ì‚¬ìš©
    sql_file = SQL_DIR / "insights_sqlite.sql"

    insight_names = [
        "ì¸ì‚¬ì´íŠ¸ 1",  # ì‹¤ì—…ë¥  ê°ì†Œì— ê¸°ì—¬í•œ ì‚°ì—…
        "ì¸ì‚¬ì´íŠ¸ 2",  # ì‹¤ì—…ë¥  ë³€ë™ì„±
        "ì¸ì‚¬ì´íŠ¸ 3",  # ì‚°ì—… ë‹¤ê°í™” ì§€ìˆ˜
        "ì¸ì‚¬ì´íŠ¸ 4",  # ê³ ìš© íšŒë³µë ¥
        "ì¸ì‚¬ì´íŠ¸ 5",  # ê²½ì œí™œë™ì°¸ê°€ìœ¨ ë³€í™”
    ]

    for name in insight_names:
        try:
            insights[name] = execute_query_from_file(engine, sql_file, name)
        except Exception as e:
            logger.error(f"âœ— {name} ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    return insights


def print_insights(insights: Dict[str, pd.DataFrame]) -> None:
    """ì¸ì‚¬ì´íŠ¸ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""

    print("\n" + "=" * 80)
    print("ğŸ“Š ë…¸ë™ì‹œì¥ ë°ì´í„° ë¶„ì„ ê²°ê³¼ (ì„ë² ë””ë“œ SQL ê¸°ë°˜)")
    print("=" * 80 + "\n")

    for i, (name, df) in enumerate(insights.items(), 1):
        print(f"[{i}] {name}")
        print("-" * 80)
        print(df.to_string(index=False))
        print()

        # ê°„ë‹¨í•œ í•´ì„ ì¶”ê°€
        if "ì¸ì‚¬ì´íŠ¸ 1" in name and len(df) > 0:
            print(f"ğŸ’¡ {df.iloc[0]['industry_name']}ì´(ê°€) ê°€ì¥ ë§ì€ ê³ ìš©ì„ ì°½ì¶œí–ˆìŠµë‹ˆë‹¤.")
            print(f"   ì´ {df.iloc[0]['total_employment_change']:,.0f}ëª… ì¦ê°€\n")

        elif "ì¸ì‚¬ì´íŠ¸ 2" in name and len(df) > 0:
            volatile_regions = df[df['volatility_level'] == 'ë†’ìŒ']
            if len(volatile_regions) > 0:
                print(f"ğŸ’¡ {len(volatile_regions)}ê°œ ì§€ì—­ì´ ë†’ì€ ì‹¤ì—…ë¥  ë³€ë™ì„±ì„ ë³´ì…ë‹ˆë‹¤.")
                print(f"   ê°€ì¥ ë¶ˆì•ˆì •: {volatile_regions.iloc[0]['region_name']}\n")

        elif "ì¸ì‚¬ì´íŠ¸ 3" in name and len(df) > 0:
            most_diverse = df.iloc[0]
            print(f"ğŸ’¡ ê°€ì¥ ë‹¤ê°í™”ëœ ì§€ì—­: {most_diverse['region_name']}")
            print(f"   ë‹¤ê°í™” ì§€ìˆ˜: {most_diverse['diversification_index']}\n")

        elif "ì¸ì‚¬ì´íŠ¸ 4" in name and len(df) > 0:
            best_recovery = df.iloc[0]
            print(f"ğŸ’¡ ê³ ìš© íšŒë³µì´ ê°€ì¥ ê°•í•œ ì§€ì—­: {best_recovery['region_name']}")
            print(f"   íšŒë³µë¥ : {best_recovery['recovery_rate_pct']}%\n")

        elif "ì¸ì‚¬ì´íŠ¸ 5" in name and len(df) > 0:
            top_increase = df.iloc[0]
            print(f"ğŸ’¡ ê²½ì œí™œë™ì°¸ê°€ìœ¨ ì¦ê°€ 1ìœ„: {top_increase['region_name']}")
            print(f"   ì¦ê°€í­: {top_increase['rate_change']}%p\n")

    print("=" * 80)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("=" * 80 + "\n")


def run_basic_statistics(engine: Engine) -> None:
    """ê¸°ë³¸ í†µê³„ ìš”ì•½"""

    print("\n" + "=" * 80)
    print("ğŸ“ˆ ê¸°ë³¸ í†µê³„")
    print("=" * 80 + "\n")

    # ì „ì²´ ë°ì´í„° ê°œìˆ˜
    with engine.connect() as conn:
        stats = pd.read_sql_query(text("""
            SELECT
                (SELECT COUNT(*) FROM fact_unemployment_monthly) as unemployment_rows,
                (SELECT COUNT(*) FROM fact_employment_by_industry_monthly) as employment_rows,
                (SELECT COUNT(*) FROM dim_industry) as industries,
                (SELECT COUNT(*) FROM dim_region) as regions
        """), conn)

    print("ë°ì´í„° í˜„í™©:")
    print(f"  - ì‹¤ì—…ë¥  ë°ì´í„°: {stats['unemployment_rows'][0]:,}í–‰")
    print(f"  - ê³ ìš© ë°ì´í„°: {stats['employment_rows'][0]:,}í–‰")
    print(f"  - ì‚°ì—… ìˆ˜: {stats['industries'][0]}ê°œ")
    print(f"  - ì§€ì—­ ìˆ˜: {stats['regions'][0]}ê°œ\n")


if __name__ == "__main__":
    from db_loader import DBConfig

    # ì„¤ì • (SQLite - ë¹„ë°€ë²ˆí˜¸ ë¶ˆí•„ìš”!)
    config = DBConfig()
    engine = config.make_engine()

    # ê¸°ë³¸ í†µê³„
    run_basic_statistics(engine)

    # ì¸ì‚¬ì´íŠ¸ ë¶„ì„
    insights = run_all_insights(engine)
    print_insights(insights)
